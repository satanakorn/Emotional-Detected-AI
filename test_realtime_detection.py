#!/usr/bin/env python3

import cv2
import numpy as np
import time
import os
import sys
from datetime import datetime

class RealtimeDetectionTester:
    def __init__(self):
        self.cap = None
        self.face_cascade = None
        self.camera_method = None
        self.load_face_cascade()
        
        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time detection
        self.frame_count = 0
        self.detection_count = 0
        self.last_detection_time = 0
        self.detection_interval = 0.05  # 50ms (20 FPS)
        
        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        self.last_save_time = time.time()
        self.save_interval = 5.0  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
        self.current_emotion = "No Face"
        self.current_confidence = 0.0
    
    def load_face_cascade(self):
        """‡πÇ‡∏´‡∏•‡∏î Haar cascade ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
        try:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ cv2.data ‡∏Å‡πà‡∏≠‡∏ô
            try:
                cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                if os.path.exists(cascade_path):
                    self.face_cascade = cv2.CascadeClassifier(cascade_path)
                    print("‚úÖ Face cascade loaded from cv2.data")
                    return
            except AttributeError:
                pass
            
            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
            print("üì• Downloading Haar cascade file...")
            import urllib.request
            url = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
            cascade_path = "haarcascade_frontalface_default.xml"
            urllib.request.urlretrieve(url, cascade_path)
            self.face_cascade = cv2.CascadeClassifier(cascade_path)
            print("‚úÖ Face cascade downloaded and loaded")
            
        except Exception as e:
            print(f"‚ùå Error loading face cascade: {e}")
            self.face_cascade = None
    
    def enhance_frame_for_detection(self, frame):
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô"""
        try:
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå
            enhanced = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)
            
            # ‡∏•‡∏î noise
            enhanced = cv2.bilateralFilter(enhanced, 9, 75, 75)
            
            return enhanced
        except Exception as e:
            print(f"Frame enhancement error: {e}")
            return frame
    
    def detect_faces_realtime(self, frame):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö real-time"""
        try:
            if self.face_cascade is None:
                return []
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
            current_time = time.time()
            if current_time - self.last_detection_time < self.detection_interval:
                return []
            
            self.last_detection_time = current_time
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
            enhanced_frame = self.enhance_frame_for_detection(frame)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö face detection
            if len(enhanced_frame.shape) == 3:
                gray = cv2.cvtColor(enhanced_frame, cv2.COLOR_BGR2GRAY)
            else:
                gray = enhanced_frame
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            faces = self.face_cascade.detectMultiScale(
                gray, 
                scaleFactor=1.05,
                minNeighbors=2,
                minSize=(30, 30),
                maxSize=(300, 300),
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            return faces
        except Exception as e:
            print(f"Face detection error: {e}")
            return []
    
    def draw_face_boxes(self, frame, faces):
        """‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ"""
        if len(faces) > 0:
            # ‡∏´‡∏≤‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å)
            largest_face = max(faces, key=lambda face: face[2] * face[3])
            x, y, w, h = largest_face
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å (‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÄ‡∏Ç‡πâ‡∏°)
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
            cv2.putText(frame, "FACE DETECTED", (x, y-15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ (‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô)
            for (fx, fy, fw, fh) in faces:
                if (fx, fy, fw, fh) != (x, y, w, h):  # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å
                    cv2.rectangle(frame, (fx, fy), (fx+fw, fy+fh), (0, 200, 0), 1)
                    cv2.putText(frame, "Face", (fx, fy-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 0), 1)
            
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            self.current_emotion = "Face Detected"
            self.current_confidence = 65.0
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
            cv2.putText(frame, f"Faces: {len(faces)}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        else:
            # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            self.current_emotion = "No Face"
            self.current_confidence = 0.0
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° "No Face Detected"
            height, width = frame.shape[:2]
            cv2.putText(frame, "NO FACE DETECTED", (width//2 - 150, height//2), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            cv2.putText(frame, "Please position your face in front of camera", 
                       (width//2 - 200, height//2 + 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)
        
        return frame
    
    def setup_camera(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
        print("üîç Setting up camera...")
        
        # ‡∏•‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á USB ‡πÅ‡∏ö‡∏ö‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏Å‡πà‡∏≠‡∏ô
        for i in range(5):
            print(f"   Testing camera index {i}...")
            self.cap = cv2.VideoCapture(i)
            
            if self.cap.isOpened():
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞ FPS
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.cap.set(cv2.CAP_PROP_FPS, 30)
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                
                ret, frame = self.cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ Camera found at index {i} - Shape: {frame.shape}")
                    self.camera_method = f"usb_{i}"
                    return True
                self.cap.release()
            else:
                print(f"   Camera {i} not available")
        
        print("‚ùå No working camera found")
        return False
    
    def save_data_if_needed(self):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ"""
        current_time = time.time()
        if current_time - self.last_save_time >= self.save_interval:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"üíæ Data saved: {self.current_emotion} ({self.current_confidence:.1f}%) - {timestamp}")
            self.last_save_time = current_time
            return True
        return False
    
    def run_test(self):
        """‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö real-time detection"""
        print("üß™ Real-time Face Detection Test")
        print("=" * 40)
        
        if not self.setup_camera():
            return False
        
        print("üì∑ Camera ready, starting real-time detection...")
        print("üíæ Data will be saved every 5 seconds")
        print("Press 'q' to quit, 's' to save screenshot")
        
        start_time = time.time()
        last_fps_update = time.time()
        fps = 0
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("‚ùå Error: Can't receive frame")
                    continue
                
                self.frame_count += 1
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö real-time
                faces = self.detect_faces_realtime(frame)
                if len(faces) > 0:
                    self.detection_count += 1
                
                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                display_frame = self.draw_face_boxes(frame.copy(), faces)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                height, width = display_frame.shape[:2]
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                current_time = time.time()
                detection_rate = (self.detection_count / self.frame_count) * 100 if self.frame_count > 0 else 0
                
                cv2.putText(display_frame, f"Detection Rate: {detection_rate:.1f}%", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(display_frame, f"Frames: {self.frame_count}", 
                           (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(display_frame, f"FPS: {fps:.1f}", 
                           (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                time_since_save = current_time - self.last_save_time
                save_status = f"Next save in: {self.save_interval - time_since_save:.1f}s"
                cv2.putText(display_frame, save_status, (10, 120), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                cv2.putText(display_frame, f"Current: {self.current_emotion}", 
                           (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(display_frame, f"Confidence: {self.current_confidence:.1f}%", 
                           (10, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                cv2.imshow('Real-time Face Detection Test', display_frame)
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                self.save_data_if_needed()
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó FPS ‡∏ó‡∏∏‡∏Å 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                if current_time - last_fps_update >= 1.0:
                    fps = self.frame_count / (current_time - start_time)
                    self.frame_count = 0
                    start_time = current_time
                    last_fps_update = current_time
                    print(f"üìä FPS: {fps:.1f}, Detection Rate: {detection_rate:.1f}%")
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    filename = f"realtime_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
                    cv2.imwrite(filename, display_frame)
                    print(f"üì∏ Screenshot saved: {filename}")
        
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è Test interrupted")
        
        finally:
            cv2.destroyAllWindows()
            if self.cap:
                self.cap.release()
            
            # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
            total_time = time.time() - start_time
            final_detection_rate = (self.detection_count / self.frame_count) * 100 if self.frame_count > 0 else 0
            
            print(f"\nüìä Final Results:")
            print(f"   Total time: {total_time:.1f} seconds")
            print(f"   Frames processed: {self.frame_count}")
            print(f"   Faces detected: {self.detection_count}")
            print(f"   Detection rate: {final_detection_rate:.1f}%")
            print(f"   Average FPS: {self.frame_count / total_time:.1f}")
            
            if final_detection_rate > 80:
                print("‚úÖ Real-time detection working excellently!")
            elif final_detection_rate > 50:
                print("‚ö†Ô∏è Real-time detection working well")
            else:
                print("‚ùå Real-time detection needs improvement")
            
            return final_detection_rate > 50

def main():
    print("üß™ Real-time Face Detection Test Tool")
    print("üéØ Test real-time detection with 5-second data saving")
    print("=" * 60)
    
    tester = RealtimeDetectionTester()
    success = tester.run_test()
    
    if success:
        print("\n‚úÖ Real-time detection test completed successfully!")
    else:
        print("\n‚ùå Real-time detection test failed")
        print("üí° Check camera connection and lighting conditions")

if __name__ == "__main__":
    main()
