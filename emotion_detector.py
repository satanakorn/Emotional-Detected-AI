#!/usr/bin/env python3

import cv2
import numpy as np
import time
import os
import sys
from datetime import datetime
import subprocess
import threading
import pandas as pd
import openpyxl
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment
from collections import deque
import queue

# ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
FRAME_SKIP = 2  # ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏∏‡∏Å 2 ‡πÄ‡∏ü‡∏£‡∏°
EMOTION_CACHE_SIZE = 5  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏Ñ‡∏ä
EXCEL_SAVE_INTERVAL = 10  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Excel ‡∏ó‡∏∏‡∏Å 10 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
MAX_QUEUE_SIZE = 100  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

try:
    from picamera2 import Picamera2
    from libcamera import controls
    PICAMERA2_AVAILABLE = True
    print("‚úÖ PiCamera2 library loaded successfully")
except ImportError:
    PICAMERA2_AVAILABLE = False
    print("‚ö†Ô∏è PiCamera2 not available, falling back to OpenCV")

try:
    from deepface import DeepFace
    DEEPFACE_AVAILABLE = True
    print("‚úÖ DeepFace library loaded successfully")
except ImportError:
    DEEPFACE_AVAILABLE = False
    print("‚ö†Ô∏è DeepFace not installed. Using simple face detection only.")
    print("Install with: pip install deepface tensorflow")

class RaspberryPi4CameraDetector:
    def __init__(self):
        self.cap = None
        self.picam2 = None
        self.camera_method = None
        self.face_cascade = None
        self.emotion_history = deque(maxlen=100)  # ‡πÉ‡∏ä‡πâ deque ‡πÅ‡∏ó‡∏ô list
        self.is_running = False
        self.frame_buffer = None
        self.buffer_lock = threading.Lock()
        self.color_mode = "color"
        self.auto_exposure = True
        self.brightness = 0.0
        self.contrast = 1.0
        self.camera_type = None
        self.excel_file = "emotion_data.xlsx"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        self.frame_count = 0
        self.last_emotion_time = 0
        self.emotion_cache = {}  # ‡πÅ‡∏Ñ‡∏ä‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
        self.data_queue = queue.Queue(maxsize=MAX_QUEUE_SIZE)
        self.excel_save_counter = 0
        
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ò‡∏£‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        self.save_thread = threading.Thread(target=self._save_data_worker, daemon=True)
        self.save_thread.start()
        
        self.load_face_cascade()
        self.initialize_excel()

    def _save_data_worker(self):
        """‡πÄ‡∏ò‡∏£‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Excel"""
        while self.is_running:
            try:
                data = self.data_queue.get(timeout=1)
                if data:
                    self._save_to_excel_internal(*data)
                    self.excel_save_counter += 1
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏∏‡∏Å‡πÜ EXCEL_SAVE_INTERVAL ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
                    if self.excel_save_counter >= EXCEL_SAVE_INTERVAL:
                        self._save_excel_file()
                        self.excel_save_counter = 0
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")

    def _save_excel_file(self):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel"""
        try:
            if hasattr(self, '_wb'):
                self._wb.save(self.excel_file)
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel: {e}")

    def initialize_excel(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏´‡∏°‡πà‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ"""
        try:
            if not os.path.exists(self.excel_file):
                self._wb = Workbook()
                ws = self._wb.active
                ws.title = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"
                
                headers = [
                    "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡πÄ‡∏ß‡∏•‡∏≤", "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (%)", 
                    "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏•‡πâ‡∏≠‡∏á"
                ]
                
                header_font = Font(bold=True, size=12)
                header_fill = PatternFill(start_color="CCE5FF", end_color="CCE5FF", fill_type="solid")
                
                for col, header in enumerate(headers, 1):
                    cell = ws.cell(row=1, column=col)
                    cell.value = header
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal='center')
                
                for col in range(1, len(headers) + 1):
                    ws.column_dimensions[chr(64 + col)].width = 15
                
                self._wb.save(self.excel_file)
                print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏´‡∏°‡πà: {self.excel_file}")
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Excel: {e}")

    def save_to_excel(self, emotion, confidence, satisfaction_level, satisfaction_text):
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"""
        try:
            now = datetime.now()
            data = (
                now.strftime("%Y-%m-%d"),
                now.strftime("%H:%M:%S"),
                emotion,
                f"{confidence:.2f}",
                satisfaction_level,
                satisfaction_text,
                self.camera_method
            )
            self.data_queue.put(data, block=False)
        except queue.Full:
            print("‚ö†Ô∏è ‡∏Ñ‡∏¥‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ï‡πá‡∏° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

    def _save_to_excel_internal(self, date, time, emotion, confidence, satisfaction_level, satisfaction_text, camera_method):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel"""
        try:
            if not hasattr(self, '_wb'):
                self._wb = openpyxl.load_workbook(self.excel_file)
            ws = self._wb.active
            
            next_row = ws.max_row + 1
            data = [date, time, emotion, confidence, satisfaction_level, satisfaction_text, camera_method]
            
            for col, value in enumerate(data, 1):
                cell = ws.cell(row=next_row, column=col)
                cell.value = value
                cell.alignment = Alignment(horizontal='center')
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Excel: {e}")

    def load_face_cascade(self):
        """‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ cv2.data ‡πÉ‡∏ô Raspberry Pi 4"""
        try:
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ cascade files ‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ   
            possible_paths = [
                '/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml',
                '/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_default.xml',
                '/home/pi/.local/lib/python3.*/site-packages/cv2/data/haarcascade_frontalface_default.xml'
            ]
            
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ cv2.data ‡∏Å‡πà‡∏≠‡∏ô
            try:
                cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                if os.path.exists(cascade_path):
                    self.face_cascade = cv2.CascadeClassifier(cascade_path)
                    print("‚úÖ Face cascade loaded from cv2.data")
                    return
            except AttributeError:
                pass
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏≠‡∏∑‡πà‡∏ô
            for path in possible_paths:
                if os.path.exists(path):
                    self.face_cascade = cv2.CascadeClassifier(path)
                    print(f"‚úÖ Face cascade loaded from {path}")
                    return
            
            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠
            print("üì• Downloading Haar cascade file...")
            import urllib.request
            url = "https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml"
            cascade_path = "haarcascade_frontalface_default.xml"
            urllib.request.urlretrieve(url, cascade_path)
            self.face_cascade = cv2.CascadeClassifier(cascade_path)
            print("‚úÖ Face cascade downloaded and loaded")
            
        except Exception as e:
            print(f"‚ùå Error loading face cascade: {e}")
            self.face_cascade = None
    
    def check_camera_hardware(self):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏ô Raspberry Pi 4"""
        print("üîç Enhanced camera status check...")
        print("=" * 50)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö libcamera
        try:
            result = subprocess.run(['libcamera-hello', '--list-cameras'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                print("‚úÖ libcamera tools available")
                print("üì∑ Available cameras:")
                print(result.stdout)
            else:
                print("‚ö†Ô∏è libcamera available but no cameras detected")
        except (subprocess.TimeoutExpired, FileNotFoundError):
            print("‚ùå libcamera tools not found")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö video devices
        print("\nüìπ Video devices:")
        os.system("ls -la /dev/video* 2>/dev/null || echo '‚ö†Ô∏è No video devices found'")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö vcgencmd
        print("\n‚öôÔ∏è Camera configuration:")
        os.system("vcgencmd get_camera 2>/dev/null || echo '‚ö†Ô∏è Cannot get camera status'")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö config.txt
        print("\nüìù Config.txt camera settings:")
        os.system("grep -E '(camera|start_x|gpu_mem)' /boot/config.txt 2>/dev/null || echo '‚ö†Ô∏è No camera settings found'")
        
        print("=" * 50)
    
    def setup_picamera2(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ PiCamera2 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Raspberry Pi 4 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏µ"""
        try:
            if not PICAMERA2_AVAILABLE:
                return False
            
            print("üîÑ Trying PiCamera2 method...")
            
            self.picam2 = Picamera2()
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ preview config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            if self.color_mode == "grayscale":
                config = self.picam2.create_preview_configuration(
                    main={"size": (640, 480), "format": "YUV420"},
                    controls={"FrameRate": 30}
                )
            else:
                config = self.picam2.create_preview_configuration(
                    main={"size": (640, 480), "format": "RGB888"},
                    controls={"FrameRate": 30}
                )
            
            self.picam2.configure(config)
            
            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ controls ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏µ
            control_settings = {
                "AeEnable": self.auto_exposure,
                "AwbEnable": True,  # Auto White Balance
                "AwbMode": controls.AwbModeEnum.Auto,
                "Brightness": self.brightness,
                "Contrast": self.contrast,
                "Saturation": 1.0,
                "Sharpness": 1.0
            }
            
            self.picam2.set_controls(control_settings)
            
            self.picam2.start()
            time.sleep(2)  # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á
            
            # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û
            frame = self.picam2.capture_array()
            if frame is not None and frame.size > 0:
                print(f"‚úÖ PiCamera2 method successful - Format: {frame.shape}")
                print(f"üì∑ Color mode: {self.color_mode}")
                self.camera_method = "picamera2"
                self.start_frame_capture_thread()
                return True
            else:
                self.picam2.stop()
                return False
                
        except Exception as e:
            print(f"   PiCamera2 error: {e}")
            if self.picam2:
                try:
                    self.picam2.stop()
                except:
                    pass
            return False
    
    def start_frame_capture_thread(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ò‡∏£‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á"""
        def capture_frames():
            while self.is_running:
                try:
                    if self.picam2:
                        frame = self.picam2.capture_array()
                        with self.buffer_lock:
                            self.frame_buffer = frame.copy()
                    time.sleep(0.03)  # ~30 FPS
                except Exception as e:
                    print(f"Frame capture error: {e}")
                    break
        
        self.is_running = True
        self.capture_thread = threading.Thread(target=capture_frames, daemon=True)
        self.capture_thread.start()
    
    def setup_opencv_camera(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ OpenCV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Raspberry Pi 4 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏µ"""
        try:
            print("üîÑ Trying OpenCV with V4L2...")
            
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ GStreamer pipeline ‡∏Å‡πà‡∏≠‡∏ô
            if self.color_mode == "grayscale":
                gst_pipeline = (
                    "libcamerasrc ! "
                    "video/x-raw,width=640,height=480,framerate=30/1,format=GRAY8 ! "
                    "videoconvert ! appsink"
                )
            else:
                gst_pipeline = (
                    "libcamerasrc ! "
                    "video/x-raw,width=640,height=480,framerate=30/1 ! "
                    "videoconvert ! appsink"
                )
            
            self.cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)
            
            if self.cap.isOpened():
                ret, frame = self.cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ GStreamer pipeline successful - Shape: {frame.shape}")
                    self.camera_method = "gstreamer"
                    return True
                self.cap.release()
            
            # ‡∏ñ‡πâ‡∏≤ GStreamer ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á V4L2
            print("üîÑ Trying V4L2 direct access...")
            
            # ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô bcm2835-v4l2 module
            os.system("sudo modprobe bcm2835-v4l2 2>/dev/null")
            time.sleep(2)
            
            self.cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
            
            if self.cap.isOpened():
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞ FPS
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.cap.set(cv2.CAP_PROP_FPS, 30)
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
                
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏µ
                self.cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.5)
                self.cap.set(cv2.CAP_PROP_CONTRAST, 0.5)
                self.cap.set(cv2.CAP_PROP_SATURATION, 0.5)
                self.cap.set(cv2.CAP_PROP_AUTO_WB, 1.0)
                
                ret, frame = self.cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ V4L2 method successful - Shape: {frame.shape}")
                    self.camera_method = "v4l2"
                    return True
                self.cap.release()
            
            # ‡∏•‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á USB
            print("üîÑ Trying USB cameras...")
            for i in range(4):
                self.cap = cv2.VideoCapture(i)
                if self.cap.isOpened():
                    self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                    self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                    ret, frame = self.cap.read()
                    if ret and frame is not None:
                        print(f"‚úÖ USB camera found at index {i} - Shape: {frame.shape}")
                        self.camera_method = f"usb_{i}"
                        return True
                    self.cap.release()
            
            return False
            
        except Exception as e:
            print(f"   OpenCV camera error: {e}")
            if self.cap:
                self.cap.release()
            return False
    
    def setup_laptop_camera(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÇ‡∏ô‡πä‡∏ï‡∏ö‡∏∏‡πä‡∏Ñ"""
        try:
            print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°...")
            self.cap = cv2.VideoCapture(0)  # ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
            
            if self.cap.isOpened():
                # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞ FPS
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.cap.set(cv2.CAP_PROP_FPS, 30)
                
                ret, frame = self.cap.read()
                if ret and frame is not None:
                    print(f"‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û: {frame.shape}")
                    self.camera_method = "laptop_webcam"
                    return True
                self.cap.release()
            
            return False
            
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°: {e}")
            if self.cap:
                self.cap.release()
            return False
    
    def setup_camera(self):
        """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
        print("üîç Camera setup...")
        
        if self.camera_type == "laptop":
            return self.setup_laptop_camera()
        elif self.camera_type == "pi":
            # ‡∏•‡∏≠‡∏á PiCamera2 ‡∏Å‡πà‡∏≠‡∏ô (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RPi 4)
            if self.setup_picamera2():
                return True
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á OpenCV
            if self.setup_opencv_camera():
                return True
        
        print("‚ùå No camera found. Troubleshooting steps:")
        print("   1. Check camera cable connection")
        print("   2. Enable camera: sudo raspi-config")
        print("   3. Add to /boot/config.txt: camera_auto_detect=1")
        print("   4. Increase GPU memory: gpu_mem=128")
        print("   5. Reboot system")
        return False
    
    def get_frame(self):
        """‡∏£‡∏±‡∏ö‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏µ"""
        frame = None
        
        if self.camera_method == "picamera2":
            with self.buffer_lock:
                if self.frame_buffer is not None:
                    frame = self.frame_buffer.copy()
        elif self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            if not ret:
                frame = None
        
        if frame is None:
            return None
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        if self.color_mode == "grayscale":
            if len(frame.shape) == 3:
                if self.camera_method == "picamera2":
                    # PiCamera2 RGB to Grayscale
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
                else:
                    # OpenCV BGR to Grayscale
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô 3 channels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
        
        elif self.color_mode == "color":
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô BGR ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenCV
            if self.camera_method == "picamera2" and len(frame.shape) == 3:
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å RGB ‡πÄ‡∏õ‡πá‡∏ô BGR
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        
        return frame
    
    def detect_emotion_deepface(self, frame):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢ DeepFace ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Ñ‡∏ä‡∏ä‡∏¥‡πà‡∏á"""
        try:
            if not DEEPFACE_AVAILABLE:
                return self.detect_faces_simple(frame)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏Ñ‡∏ä
            frame_hash = hash(frame.tobytes())
            if frame_hash in self.emotion_cache:
                return self.emotion_cache[frame_hash]
            
            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ñ‡πâ‡∏≤‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            current_time = time.time()
            if current_time - self.last_emotion_time < 0.1:  # 100ms
                return None
            
            self.last_emotion_time = current_time
            
            if self.camera_method == "picamera2":
                if len(frame.shape) == 3 and frame.shape[2] == 3:
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                else:
                    frame_bgr = frame
            else:
                frame_bgr = frame
                
            result = DeepFace.analyze(
                frame_bgr, 
                actions=['emotion'], 
                enforce_detection=False,
                silent=True
            )
            
            if isinstance(result, list) and len(result) > 0:
                emotion_map = {
                    'angry': 'Angry',
                    'disgust': 'Disgust',
                    'fear': 'Fear',
                    'happy': 'Happy',
                    'sad': 'Sad',
                    'surprise': 'Surprise',
                    'neutral': 'Neutral'
                }
                
                emotion = result[0]['dominant_emotion']
                confidence = result[0]['emotion'][emotion]
                satisfaction_level = min(5, max(1, int(confidence / 20) + 1))
                satisfaction_text = "‚òÖ" * satisfaction_level
                
                result = (
                    emotion_map.get(emotion, emotion),
                    confidence,
                    satisfaction_level,
                    satisfaction_text
                )
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô‡πÅ‡∏Ñ‡∏ä
                self.emotion_cache[frame_hash] = result
                if len(self.emotion_cache) > EMOTION_CACHE_SIZE:
                    self.emotion_cache.pop(next(iter(self.emotion_cache)))
                
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                self.save_to_excel(*result)
                
                return result
            else:
                return "No Face", 0.0, 0, ""
                
        except Exception as e:
            print(f"DeepFace error: {e}")
            return self.detect_faces_simple(frame)
    
    def detect_faces_simple(self, frame):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏µ"""
        try:
            if self.face_cascade is None:
                return "no_cascade", 0.0
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö face detection
            if len(frame.shape) == 3:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            else:
                gray = frame
                
            faces = self.face_cascade.detectMultiScale(
                gray, 
                scaleFactor=1.1, 
                minNeighbors=5, 
                minSize=(30, 30)
            )
            
            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö
            if len(faces) > 0:
                for (x, y, w, h) in faces:
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö
                    cv2.putText(frame, "Face", (x, y-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
            return "face_detected", len(faces) if len(faces) > 0 else 0.0
                
        except Exception as e:
            print(f"Face detection error: {e}")
            return "error", 0.0
    
    def add_overlay_info(self, frame, emotion, confidence, satisfaction_level, satisfaction_text):
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡∏ö‡∏ô‡πÄ‡∏ü‡∏£‡∏° ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏µ"""
        if frame is None:
            return frame
        
        height, width = frame.shape[:2]
        
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (width-10, 200), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ‡∏Å‡∏£‡∏≠‡∏ö‡∏Ç‡∏≠‡∏ö
        cv2.rectangle(frame, (10, 10), (width-10, 200), (255, 255, 255), 2)
        
        # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏™‡∏î‡πÉ‡∏™)
        emotion_text = f"Emotion: {emotion}"
        cv2.putText(frame, emotion_text, (20, 40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)
        if isinstance(confidence, (int, float)) and confidence > 0:
            conf_text = f"Confidence: {confidence:.2f}%"
            cv2.putText(frame, conf_text, (20, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à (‡∏™‡∏µ‡∏ü‡πâ‡∏≤)
        satisfaction_level_text = f"Satisfaction: {satisfaction_level}/5"
        cv2.putText(frame, satisfaction_level_text, (20, 100), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ‡∏î‡∏≤‡∏ß‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à (‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)
        stars_text = f"Score: {satisfaction_text}"
        cv2.putText(frame, stars_text, (20, 130), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß)
        camera_text = f"Camera: {self.camera_method}"
        cv2.putText(frame, camera_text, (20, 160), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ (‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á)
        color_text = f"Mode: {self.color_mode}"
        cv2.putText(frame, color_text, (20, 180), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)
        
        # ‡πÄ‡∏ß‡∏•‡∏≤ (‡∏™‡∏µ‡∏ü‡πâ‡∏≤)
        time_text = datetime.now().strftime("%H:%M:%S")
        cv2.putText(frame, time_text, (width-150, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        return frame
    
    def save_emotion_data(self, emotion, confidence):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        timestamp = datetime.now().isoformat()
        data = {
            'timestamp': timestamp,
            'emotion': emotion,
            'confidence': confidence,
            'camera_method': self.camera_method
        }
        self.emotion_history.append(data)
        
        if len(self.emotion_history) > 100:
            self.emotion_history.pop(0)
    
    def run(self):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
        print("üé≠ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á")
        print("=" * 60)
        
        if not self.setup_camera():
            return
        
        print(f"üì∑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {self.camera_method}")
        print("üéØ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå...")
        print("üìã ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°:")
        print("   - ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")
        print("   - ‡∏Å‡∏î 's' ‡∏´‡∏£‡∏∑‡∏≠ SPACE ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
        print("   - ‡∏Å‡∏î 'i' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡πâ‡∏≠‡∏á")
        print("   - ‡∏Å‡∏î 'c' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ")
        print("   - ‡∏Å‡∏î 'b'/'v' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á (+/-)")
        print("   - ‡∏Å‡∏î 'n'/'m' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå (+/-)")
        print("=" * 60)
        
        self.is_running = True
        frame_count = 0
        fps_start_time = time.time()
        last_fps_update = time.time()
        fps = 0
        
        try:
            while True:
                frame = self.get_frame()
                
                if frame is None:
                    print("‚ùå Error: Can't receive frame")
                    time.sleep(0.1)
                    continue
                
                frame_count += 1
                
                # ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
                if frame_count % FRAME_SKIP != 0:
                    continue
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå
                result = self.detect_emotion_deepface(frame)
                if result:
                    emotion, confidence, satisfaction_level, satisfaction_text = result
                    display_frame = self.add_overlay_info(
                        frame, emotion, confidence, satisfaction_level, satisfaction_text
                    )
                    
                    if display_frame is not None:
                        cv2.imshow('Emotion Detection', display_frame)
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó FPS ‡∏ó‡∏∏‡∏Å 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                current_time = time.time()
                if current_time - last_fps_update >= 1.0:
                    fps = frame_count / (current_time - fps_start_time)
                    frame_count = 0
                    fps_start_time = current_time
                    last_fps_update = current_time
                    print(f"üìä FPS: {fps:.1f}")
                
                # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ key input
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s') or key == 32:
                    filename = f"emotion_screenshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
                    cv2.imwrite(filename, display_frame)
                    print(f"üì∏ Screenshot saved: {filename}")
                elif key == ord('i'):
                    self.show_camera_info()
                elif key == ord('c'):
                    self.toggle_color_mode()
                elif key == ord('b'):
                    self.adjust_brightness(0.1)
                elif key == ord('v'):
                    self.adjust_brightness(-0.1)
                elif key == ord('n'):
                    self.adjust_contrast(0.1)
                elif key == ord('m'):
                    self.adjust_contrast(-0.1)
                
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è Interrupted by user")
        
        finally:
            self.cleanup()
    
    def toggle_color_mode(self):
        """‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ"""
        if self.color_mode == "color":
            self.color_mode = "grayscale"
            print("üé® Switched to grayscale mode")
        else:
            self.color_mode = "color"
            print("üé® Switched to color mode")
    
    def adjust_brightness(self, delta):
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á"""
        self.brightness = max(-1.0, min(1.0, self.brightness + delta))
        print(f"üí° Brightness: {self.brightness:.1f}")
        
        if self.picam2:
            try:
                self.picam2.set_controls({"Brightness": self.brightness})
            except:
                pass
    
    def adjust_contrast(self, delta):
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå"""
        self.contrast = max(0.0, min(2.0, self.contrast + delta))
        print(f"üîÜ Contrast: {self.contrast:.1f}")
        
        if self.picam2:
            try:
                self.picam2.set_controls({"Contrast": self.contrast})
            except:
                pass
        """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
        print("\nüì∑ Camera Information:")
        print(f"   Method: {self.camera_method}")
        print(f"   Emotion history: {len(self.emotion_history)} records")
        print(f"   DeepFace available: {DEEPFACE_AVAILABLE}")
        print(f"   PiCamera2 available: {PICAMERA2_AVAILABLE}")
        
        if self.cap:
            width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            print(f"   Resolution: {int(width)}x{int(height)}")
            print(f"   FPS Setting: {fps}")
    
    def cleanup(self):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"""
        print("üßπ Cleaning up...")
        
        self.is_running = False
        
        if self.picam2:
            try:
                self.picam2.stop()
            except:
                pass
        
        if self.cap:
            self.cap.release()
        
        cv2.destroyAllWindows()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß
        try:
            while not self.data_queue.empty():
                data = self.data_queue.get_nowait()
                self._save_to_excel_internal(*data)
            self._save_excel_file()
        except:
            pass
        
        if self.emotion_history:
            print(f"üìä Total emotions detected: {len(self.emotion_history)}")
            
            emotions = [record['emotion'] for record in self.emotion_history]
            unique_emotions = set(emotions)
            print("üìà Emotion statistics:")
            for emotion in unique_emotions:
                count = emotions.count(emotion)
                percentage = (count / len(emotions)) * 100
                print(f"   {emotion}: {count} times ({percentage:.1f}%)")
        
        print("‚úÖ Cleanup completed")

def main():
    print("üé≠ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á")
    print("üé® ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 2.2 - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•")
    print("=" * 70)
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏•‡πâ‡∏≠‡∏á
    print("\nüîß ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏•‡πâ‡∏≠‡∏á:")
    print("1. ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏° (‡πÇ‡∏ô‡πä‡∏ï‡∏ö‡∏∏‡πä‡∏Ñ)")
    print("2. ‡∏Å‡∏•‡πâ‡∏≠‡∏á Raspberry Pi")
    
    while True:
        try:
            choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏•‡πâ‡∏≠‡∏á (1-2): ").strip()
            if choice == "1":
                camera_type = "laptop"
                break
            elif choice == "2":
                camera_type = "pi"
                break
            else:
                print("‚ùå ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1 ‡∏´‡∏£‡∏∑‡∏≠ 2")
        except:
            print("‚ùå ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà")
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ
    print("\nüîß ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•:")
    print("1. ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏µ (‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)")
    print("2. ‡πÇ‡∏´‡∏°‡∏î‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥")
    
    try:
        choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î (1-2, ‡∏Å‡∏î Enter ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô): ").strip()
        color_mode = "grayscale" if choice == "2" else "color"
    except:
        color_mode = "color"
    
    detector = RaspberryPi4CameraDetector()
    detector.camera_type = camera_type
    detector.color_mode = color_mode
    detector.check_camera_hardware()
    detector.run()

if __name__ == "__main__":
    main()